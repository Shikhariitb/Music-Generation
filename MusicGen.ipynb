{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicGen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The colab notebook contains implemented code based on the following article for music generation\n",
        "https://www.analyticsvidhya.com/blog/2020/01/how-to-perform-automatic-music-generation/"
      ],
      "metadata": {
        "id": "edWTH859ZEWN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iBKUBlAVayR"
      },
      "outputs": [],
      "source": [
        "from music21 import *\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "import keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "def read_midi(file):\n",
        "    \n",
        "    print(\"Loading Music File:\",file)\n",
        "    \n",
        "    notes=[]\n",
        "    notes_to_parse = None\n",
        "    \n",
        "    #parsing a midi file\n",
        "    midi = converter.parse(file)\n",
        "  \n",
        "    #grouping based on different instruments\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "\n",
        "    #Looping over all the instruments\n",
        "    for part in s2.parts:\n",
        "    \n",
        "        #select elements of only piano\n",
        "        if 'Piano' in str(part): \n",
        "        \n",
        "            notes_to_parse = part.recurse() \n",
        "      \n",
        "            #finding whether a particular element is note or a chord\n",
        "            for element in notes_to_parse:\n",
        "                \n",
        "                #note\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                \n",
        "                #chord\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return np.array(notes)\n",
        "\n",
        "path = \"/content/drive/MyDrive/ma2/\"\n",
        "files = [i for i in os.listdir(path) if i.endswith(\".midi\")]\n",
        "notes_array = np.array([read_midi(path+i) for i in files], dtype = object)\n",
        "notes = [element for note in notes_array for element in note]\n",
        "\n",
        "unique_notes = list(set(notes))\n",
        "freq = dict(Counter(notes))\n",
        "no = [count for _,count in freq.items()]\n",
        "\n",
        "frequent_notes = [note for note, count in freq.items() if count>=50]\n",
        "\n",
        "new_music = []\n",
        "\n",
        "for n in notes_array:\n",
        "    temp=[]\n",
        "    for no in n:\n",
        "        if no in frequent_notes:\n",
        "            temp.append(no)            \n",
        "    new_music.append(temp)\n",
        "    \n",
        "new_music = np.array(new_music, dtype = object)\n",
        "\n",
        "no_of_timesteps = 32\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for n in new_music:\n",
        "    for i in range(0, len(n) - no_of_timesteps, 1):\n",
        "        \n",
        "        #preparing input and output sequences\n",
        "        inp = n[i:i + no_of_timesteps]\n",
        "        out = n[i + no_of_timesteps]\n",
        "        \n",
        "        x.append(inp)\n",
        "        y.append(out)\n",
        "        \n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "unique_x = list(set(x.ravel()))\n",
        "x_note_to_int = dict((note, num) for num, note in enumerate(unique_x))\n",
        "\n",
        "#preparing input sequences\n",
        "x_seq=[]\n",
        "for i in x:\n",
        "    temp=[]\n",
        "    for j in i:\n",
        "        #assigning unique integer to every note\n",
        "        temp.append(x_note_to_int[j])\n",
        "    x_seq.append(temp)\n",
        "    \n",
        "x_seq = np.array(x_seq)\n",
        "\n",
        "unique_y = list(set(y))\n",
        "y_note_to_int = dict((note, num) for num, note in enumerate(unique_y)) \n",
        "y_seq = np.array([y_note_to_int[i] for i in y])\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)\n",
        "\n",
        "# model = Sequential()\n",
        "    \n",
        "# #embedding layer\n",
        "# model.add(Embedding(len(unique_x), 100, input_length = 32,trainable = True)) \n",
        "\n",
        "# model.add(Conv1D(64,3, padding = 'causal', activation = 'relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(MaxPool1D(2))\n",
        "    \n",
        "# model.add(Conv1D(128,3, activation = 'relu', dilation_rate = 2, padding = 'causal'))\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(MaxPool1D(2))\n",
        "\n",
        "# model.add(Conv1D(256,3, activation = 'relu', dilation_rate = 4, padding = 'causal'))\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(MaxPool1D(2))\n",
        "          \n",
        "# #model.add(Conv1D(256,5,activation='relu'))    \n",
        "# model.add(GlobalMaxPool1D())\n",
        "    \n",
        "# model.add(Dense(256, activation = 'relu'))\n",
        "# model.add(Dense(len(unique_y), activation = 'softmax'))\n",
        "    \n",
        "# model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(unique_x), 100, input_length = 32,trainable = True))\n",
        "model.add(LSTM(128,return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only = True, verbose = 1)\n",
        "history = model.fit(np.array(x_tr), np.array(y_tr), batch_size = 128, epochs = 150, validation_data = (np.array(x_val), np.array(y_val)), verbose = 1, callbacks = [mc], )\n",
        "\n",
        "#loading best model\n",
        "from keras.models import load_model\n",
        "model = load_model('best_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLnxDtJ2mQQ4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "import keras.backend as K\n",
        "\n",
        "model = Sequential()\n",
        "    \n",
        "#embedding layer\n",
        "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
        "\n",
        "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "    \n",
        "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "\n",
        "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "          \n",
        "#model.add(Conv1D(256,5,activation='relu'))    \n",
        "model.add(GlobalMaxPool1D())\n",
        "    \n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(len(unique_y), activation='softmax'))\n",
        "    \n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only = True, verbose=1)\n",
        "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])\n",
        "\n",
        "#loading best model\n",
        "from keras.models import load_model\n",
        "model = load_model('best_model.h5')"
      ]
    }
  ]
}